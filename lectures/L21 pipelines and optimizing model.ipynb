{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines and exploring the lending club data\n",
    "\n",
    "1. Cool new EDA tools\n",
    "1. Proj set up - whys \n",
    "1. Setting up a pipeline (why?!?!?!?! :( )) to deal with data issues\n",
    "1. **The question: Can we predict which loans will default? Credit modeling**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lots of functions\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from df_after_transform import df_after_transform\n",
    "from sklearn.model_selection import KFold, cross_validate, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "loans = pd.read_csv('lendingclub/2013_subsample.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-profiling\n",
    "# https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html\n",
    "\n",
    "######################################\n",
    "# WARNING DO THIS ON X_TRAIN+Y_TRAIN ONLY,\n",
    "# DON'T DO EDA ON ALL DATA (IE DONT LEARN FROM TEST DATA!)\n",
    "######################################\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(loans, \n",
    "                        title='Lending Club Profiling Report',\n",
    "                        html={'style':{'full_width':True}}) \n",
    "profile.to_file(\"lending_club_INITIAL.html\") # can take a minute or two with this dataset size. Let's look at the one I uploaded...\n",
    "\n",
    "######################################\n",
    "# EDA CONCLUSIONS - any vars that might go in the model?\n",
    "# generally, ML models want no missing values, mean 0, std 1\n",
    "######################################\n",
    "\n",
    "# numerical - annual_income (heavily skewed), int_rate, loan_amnt, dti, \n",
    "\n",
    "# cat - public_rec_bankruptcies, grade \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to test and train (link to split page/sk docs)\n",
    "\n",
    "# first let's separate y from X\n",
    "y = loans.loan_status == 'Charged Off'\n",
    "y.value_counts()\n",
    "loans = loans.drop('loan_status',axis=1)\n",
    "\n",
    "# stratify will make sure that test/train both have equal fractions of outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(loans, y, stratify=y, test_size=.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-modeling (on the training data only!)\n",
    "# run ProfileReport here!!!!\n",
    "\n",
    "# do lots of EDA\n",
    "# look for missing values, which variables are what type, and outliers \n",
    "# figure out how you'd clean the data (imputation, scaling, encoding categorical vars)\n",
    "# these lessons will go into the preprocessign portion of your pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimize a series of models \n",
    "\n",
    "# set up pipeline to clean each type of variable (1 pipe per var type)\n",
    "\n",
    "numer_pipe = make_pipeline(SimpleImputer(),StandardScaler()) \n",
    "cat_pipe   = make_pipeline(OneHotEncoder(drop='first'))\n",
    "\n",
    "# combine those pipes into \"preprocess\" pipe\n",
    "\n",
    "preproc_pipe = ColumnTransformer(  \n",
    "    [ # arg 1 of ColumnTransformer is a list, so this starts the list\n",
    "    # a tuple for the numerical vars: name, pipe, which vars to apply to\n",
    "    (\"num_impute\", numer_pipe, ['annual_inc']),\n",
    "    # a tuple for the categorical vars: name, pipe, which vars to apply to\n",
    "    (\"cat_trans\", cat_pipe, ['grade'])\n",
    "    ]\n",
    "    , remainder = 'drop' # you either drop or passthrough any vars not modified above\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are {preproc_df.shape[1]} columns in the preprocessed data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>121.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_B</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_C</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_D</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_E</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_F</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade_G</th>\n",
       "      <td>107843.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count  mean   std   min   25%   50%   75%     max\n",
       "annual_inc  107843.0 -0.00  1.00 -1.36 -0.55 -0.19  0.32  121.55\n",
       "grade_B     107843.0  0.33  0.47  0.00  0.00  0.00  1.00    1.00\n",
       "grade_C     107843.0  0.28  0.45  0.00  0.00  0.00  1.00    1.00\n",
       "grade_D     107843.0  0.15  0.36  0.00  0.00  0.00  0.00    1.00\n",
       "grade_E     107843.0  0.07  0.25  0.00  0.00  0.00  0.00    1.00\n",
       "grade_F     107843.0  0.03  0.18  0.00  0.00  0.00  0.00    1.00\n",
       "grade_G     107843.0  0.01  0.08  0.00  0.00  0.00  0.00    1.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########\n",
    "# hot tip: check out what this preprocessing does before you continue!\n",
    "###########\n",
    "\n",
    "from df_after_transform import df_after_transform\n",
    "\n",
    "preproc_df = df_after_transform(preproc_pipe,X_train)\n",
    "print('There are {preproc_df.shape[1]} columns in the preprocessed data.')\n",
    "preproc_df.describe().T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cv (can set up iterable to do OOS! or TimeSeriesSplit, or...)\n",
    "\n",
    "\n",
    "\n",
    "# set up scoring \n",
    "\n",
    "# let's evaulate on \"precision\" today...https://ledatascifi.github.io/ledatascifi-2021/content/05/03d_whatToMax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('num_impute',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['annual_inc']),\n",
       "                                                 ('cat_trans',\n",
       "                                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['grade'])])),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## optimize candidate model type #1: \n",
    "\n",
    "#     set up pipeline (combines preprocessing, estimator)\n",
    "\n",
    "logit_pipe = make_pipeline(preproc_pipe, LogisticRegression())\n",
    "logit_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(logit_pipe,X_train,y_train,scoring='precision_micro',\n",
    "               cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8440418014840922"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()  # a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     set up hyper param grid - what params in a pipeline do you want to change?\n",
    "# a dictionary. keys are things to change in pipeline\n",
    "# key: <stepname>__<parametername>\n",
    "\n",
    "parameters =  {'logisticregression__C': [0.1,1,5]}\n",
    "\n",
    "#     find optimal hyper params (gridsearchcv)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = logit_pipe, \n",
    "                           param_grid = parameters,\n",
    "                           scoring='precision_micro'\n",
    "                           )\n",
    "\n",
    "results = grid_search.fit(X_train,y_train)\n",
    "\n",
    "#     save pipeline with optimal params in place\n",
    "#     (Note: you should spend time interrogating model predictions, plotting and printing.\n",
    "#     Does the model struggle predicting certain obs? Excel at some?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'logisticregression__C': 0.1}</th>\n",
       "      <td>0.528666</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>0.044998</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844028</td>\n",
       "      <td>0.844075</td>\n",
       "      <td>0.844042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'logisticregression__C': 1}</th>\n",
       "      <td>0.532052</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.046999</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844028</td>\n",
       "      <td>0.844075</td>\n",
       "      <td>0.844042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'logisticregression__C': 5}</th>\n",
       "      <td>0.562557</td>\n",
       "      <td>0.036129</td>\n",
       "      <td>0.047199</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>5</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844028</td>\n",
       "      <td>0.844075</td>\n",
       "      <td>0.844042</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "params                                                                         \n",
       "{'logisticregression__C': 0.1}       0.528666      0.013630         0.044998   \n",
       "{'logisticregression__C': 1}         0.532052      0.027821         0.046999   \n",
       "{'logisticregression__C': 5}         0.562557      0.036129         0.047199   \n",
       "\n",
       "                                std_score_time param_logisticregression__C  \\\n",
       "params                                                                       \n",
       "{'logisticregression__C': 0.1}        0.006388                         0.1   \n",
       "{'logisticregression__C': 1}          0.005896                           1   \n",
       "{'logisticregression__C': 5}          0.004832                           5   \n",
       "\n",
       "                                split0_test_score  split1_test_score  \\\n",
       "params                                                                 \n",
       "{'logisticregression__C': 0.1}           0.844035           0.844035   \n",
       "{'logisticregression__C': 1}             0.844035           0.844035   \n",
       "{'logisticregression__C': 5}             0.844035           0.844035   \n",
       "\n",
       "                                split2_test_score  split3_test_score  \\\n",
       "params                                                                 \n",
       "{'logisticregression__C': 0.1}           0.844035           0.844028   \n",
       "{'logisticregression__C': 1}             0.844035           0.844028   \n",
       "{'logisticregression__C': 5}             0.844035           0.844028   \n",
       "\n",
       "                                split4_test_score  mean_test_score  \\\n",
       "params                                                               \n",
       "{'logisticregression__C': 0.1}           0.844075         0.844042   \n",
       "{'logisticregression__C': 1}             0.844075         0.844042   \n",
       "{'logisticregression__C': 5}             0.844075         0.844042   \n",
       "\n",
       "                                std_test_score  rank_test_score  \n",
       "params                                                           \n",
       "{'logisticregression__C': 0.1}        0.000017                1  \n",
       "{'logisticregression__C': 1}          0.000017                1  \n",
       "{'logisticregression__C': 5}          0.000017                1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results.cv_results_).set_index('params')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimize candidate model type #2\n",
    "\n",
    "# ...\n",
    "\n",
    "## optimize candidate model type #N\n",
    "\n",
    "## compare the N optimized models\n",
    "\n",
    "# build list of models (each with own optimized hyperparams)\n",
    "# for model in models:\n",
    "#    cross_validate(model, X, y,...)\n",
    "# pick the winner!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
